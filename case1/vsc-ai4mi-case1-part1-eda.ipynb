{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 4 Materials Industry\n",
    "# Case study 1: Faulty steel plates\n",
    "# Notebook 1: Exploratory Data Analysis for tabular data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "The dataset consists of a series of features describing 6 well-defined classes of defects and one class containing all other faults. The dataset was made available by the [Semeion research center](http://www.semeion.it/wordpress/)\n",
    "\n",
    "The following urls provide a link to the dataset itself and some example code:\n",
    "* [Dataset at UCI ML](http://archive.ics.uci.edu/ml/datasets/steel+plates+faults \"Faulty steel plate dataset\")\n",
    "* [Kaggle page with example code](https://www.kaggle.com/uciml/faulty-steel-plates \"Kaggle\")\n",
    "\n",
    "Type of dependent variables, which we will try to predict (7 Types of Steel Plates Faults):\n",
    "1. Pastry\n",
    "2. Z_Scratch\n",
    "3. K_Scatch\n",
    "4. Stains\n",
    "5. Dirtiness\n",
    "6. Bumps\n",
    "7. Other_Faults\n",
    "\n",
    "\n",
    "27 independent variables, which we will use to make predictions:\n",
    "* X_Minimum\n",
    "* X_Maximum\n",
    "* Y_Minimum\n",
    "* Y_Maximum\n",
    "* Pixels_Areas\n",
    "* X_Perimeter\n",
    "* Y_Perimeter\n",
    "* Sum_of_Luminosity\n",
    "* Minimum_of_Luminosity\n",
    "* Maximum_of_Luminosity\n",
    "* Length_of_Conveyer\n",
    "* TypeOfSteel_A300\n",
    "* TypeOfSteel_A400\n",
    "* Steel_Plate_Thickness\n",
    "* Edges_Index\n",
    "* Empty_Index\n",
    "* Square_Index\n",
    "* Outside_X_Index\n",
    "* Edges_X_Index\n",
    "* Edges_Y_Index\n",
    "* Outside_Global_Index\n",
    "* LogOfAreas\n",
    "* Log_X_Index\n",
    "* Log_Y_Index\n",
    "* Orientation_Index\n",
    "* Luminosity_Index\n",
    "* SigmoidOfAreas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "The first step when doing machine learning is always to explore the data you're going to work with.\n",
    "\n",
    "* What is the type of data?\n",
    "* What does it represent?\n",
    "* What are the limitations?\n",
    "* Is the dataset balanced? Is each class roughly equally represented?\n",
    "* Which features correlate with each other? Does this make sense?\n",
    "* Which features correlate with which output class?\n",
    "\n",
    "Knowing what the data can and cannot tell you is crucial to know what kind of models can be built on top of it, and what these models can be capable of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary: Setting up the environment\n",
    "\n",
    "Basic functions like plotting and doing math. It's not important if not everything in this step makes sense to you right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is simply to install the packages we'll be using, this only needs to happen once.\n",
    "# It might be necessary to restart the kernel after this step\n",
    "\n",
    "! pip install seaborn\n",
    "! pip install scikit-learn\n",
    "! pip install shap\n",
    "! pip install pyarrow\n",
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np # Math functions\n",
    "import pandas as pd # Pandas is used for handling databases, and will be used for reading and manipulating the data\n",
    "import matplotlib.pyplot as plt # Plot functions\n",
    "import seaborn as sns # More plot functions\n",
    "\n",
    "sns.set_palette('colorblind') # Making the plots colorblind-friendly\n",
    "sns.set_style('darkgrid') # More info at https://seaborn.pydata.org/tutorial/aesthetics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "First, we read the data from the file `faults.csv`. For this we use pandas (`pd`) and read it as a pandas dataframe. In this case all the columns we want to read have been explicitly named, this isn't always necessary, but it helps to know exactly what is being read and what the dataframe contains.\n",
    "\n",
    "After the dataframe has been read, we use the `describe()` function to get a summary of what is contained and what sorts of values we can find in each column.\n",
    "\n",
    "It is very important to check whether there isn't any identifying column present. For example, if you want to teach a model to rank materials based on a certain property, and you start from an ordered dataset that has the rank encoded as a feature, then the model will probably simply learn to identify the rank and ignore all the \"real\" information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('faults.csv',header=0,names=['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',\n",
    "       'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity',\n",
    "       'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer',\n",
    "       'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness',\n",
    "       'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index',\n",
    "       'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas',\n",
    "       'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index',\n",
    "       'SigmoidOfAreas', 'Pastry', 'Z_Scratch', 'K_Scratch', 'Stains',\n",
    "       'Dirtiness', 'Bumps', 'Other_Faults'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense for what the actual data looks like, we can use the `head()` function, which shows us the first 5 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dealing with tabular data, data stored in a table with columns and rows.\n",
    "\n",
    "A row is a specific data point and can be addressed with `.iloc` in much the same way as a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[20:25].T # The .T operator transposes a grid, exchanging rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column is what we call a __feature__. These are typically labeled with a name and can be called as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"X_Maximum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select multiple columns at once by passing a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"X_Maximum\", \"X_Minimum\"]] # Note the brackets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And perform arithmetic on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"X_Maximum\"] - df[\"X_Minimum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even store this as a new feature. This statement creates a new feature column `X_Size` and stores the result of the operation inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"X_Size\"] = df[\"X_Maximum\"] - df[\"X_Minimum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it's also useful to consider what information is being encoded in these features. We are looking at faults on steel plates. The `X_minimum`, `X_maximum`, `Y_minimum` and `Y_maximum` tell us the boundaries of where the fault starts and ends. But it might be more useful to store the location and size, instead.\n",
    "\n",
    "### Exercise 1:\n",
    "\n",
    "Create three new features called `X_Center`, `Y_Center` and `Y_Size` which store the coordinates of the center of the defect and its size. Be aware that these feature names are case sensitive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `pandas.Dataframe.drop` command and remove the four original columns `X_minimum`, `X_maximum`, `Y_minimum` and `Y_maximum` from the dataframe, as we now have a more intuitive way of storing the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"X_Minimum\", \"X_Maximum\", \"Y_Minimum\", \"Y_Maximum\"])\n",
    "# We could keep the original features, but if we want to be able to interpret our models,\n",
    "# it helps to not have too many features that encode the same information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dataset for use in our other notebook. `pandas.DataFrame.to_csv` writes it to a standard CSV file, readable by Excel and other spreadsheet software. When reading the CSV again pandas will have to interpret how to store the data. The `pandas.Dataframe.to_Feather` method stores data in a binary format which does not require parsing and is thus much faster to read. If you want to add more features don't forget to do this before saving the file, then later you can read it again in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(\"vsc-ai4mi-case1-eda.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "Plots can be more easily interpreted than bare numbers, so it can be useful to plot an overview of certain things. For example, using a pie chart to see the distribution of classes, or a scatterplot to see how two features might relate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what a plot looks like between the orientation index and square index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='Orientation_Index',y='Square_Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it's clear that the Orientation Index encodes information about\n",
    "how elongated the defect is, and whether its long side is in the X- or Y-direction.\n",
    "The square index encodes whether the defect is strongly elongated (-1 or +1) or completely square (0).\n",
    "\n",
    "Note that a linear regression between these features would show a correlation of 0.\n",
    "This would imply they're not related at all, while it is in fact the perfect correlation in the\n",
    "first half that perfectly cancels the anti-correlation in the second half.\n",
    "This shows that it can help to not blindly rely on simplified statistics,\n",
    "but that an actual look at the data can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding\n",
    "\n",
    "This dataset uses so-called one-hot encoding, meaning that each target class has a separate column. If the specific sample is of that class, the corresponding column will have a 1, and all other columns will be 0. The other possible encoding is to have one single column to determine the class of defect, represented by a number 0 to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Pastry', 'Z_Scratch', 'K_Scratch', 'Stains',\n",
    "       'Dirtiness', 'Bumps', 'Other_Faults']].iloc[[5, 300, 500, 750, 850, 1200, 1800]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's useful to have a combined Defect_Type feature\n",
    "target = ['Pastry', 'Z_Scratch', 'K_Scratch', 'Stains',\n",
    "       'Dirtiness', 'Bumps', 'Other_Faults']\n",
    "\n",
    "df['Defect_Type'] = 0 # Create a new feature, fill it with 0\n",
    "for t in target:\n",
    "    df.loc[df[t] == 1, 'Defect_Type'] = target.index(t) # Change one-hot encoding to a combined class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of these classes with a pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts = df['Defect_Type'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(dpi=120)\n",
    "_ = plt.pie(cts, labels=target, autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "_ = df['Defect_Type'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think is the impact of the class distribution shown in the pie chart on how well a model will learn to recognize certain classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting parts of the dataframe\n",
    "\n",
    "It's also possible to give logical statements as a selector to grab specific parts of the dataframe.\n",
    "\n",
    "As an example, we can select all rows for which the type of steel is A300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This logical statement outputs a list of True and False values. \n",
    "\n",
    "df[\"TypeOfSteel_A300\"] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting this in the dataframe itself yields a selection.\n",
    "\n",
    "df[ df[\"TypeOfSteel_A300\"] == 1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine the logical row selection with a selection of feature columns, for example, to get an overview of the position of defects on A300 steel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"TypeOfSteel_A300\"] == 1][[\"X_Center\", \"Y_Center\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "What can you say about the types of steel in the dataset? Take a look at the properties of A400 steel as well. In what properties do they differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Do all defects have the same size and shape? Which are typically the largest? Which are typically the smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
